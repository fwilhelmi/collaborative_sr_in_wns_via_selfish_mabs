\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Related Work}{}% 2
\BOOKMARK [1][-]{section.3}{Multi-Armed Bandits for Improving Spatial Reuse in WNs}{}% 3
\BOOKMARK [2][-]{subsection.3.1}{The Multi-Armed Bandits Framework}{section.3}% 4
\BOOKMARK [2][-]{subsection.3.2}{Multi-Armed Bandits Formulation for Decentralized Spatial Reuse}{section.3}% 5
\BOOKMARK [3][-]{subsubsection.3.2.1}{-greedy}{subsection.3.2}% 6
\BOOKMARK [3][-]{subsubsection.3.2.2}{EXP3}{subsection.3.2}% 7
\BOOKMARK [3][-]{subsubsection.3.2.3}{UCB}{subsection.3.2}% 8
\BOOKMARK [3][-]{subsubsection.3.2.4}{Thompson sampling}{subsection.3.2}% 9
\BOOKMARK [1][-]{section.4}{System model}{}% 10
\BOOKMARK [2][-]{subsection.4.1}{Channel modeling}{section.4}% 11
\BOOKMARK [2][-]{subsection.4.2}{Throughput calculation}{section.4}% 12
\BOOKMARK [2][-]{subsection.4.3}{Learning procedure}{section.4}% 13
\BOOKMARK [2][-]{subsection.4.4}{Simulation Parameters}{section.4}% 14
\BOOKMARK [1][-]{section.5}{Performance Evaluation}{}% 15
\BOOKMARK [2][-]{subsection.5.1}{Toy Grid Scenario}{section.5}% 16
\BOOKMARK [3][-]{subsubsection.5.1.1}{Configuration of the Learning Parameters}{subsection.5.1}% 17
\BOOKMARK [3][-]{subsubsection.5.1.2}{Performance of the MAB-based Policies}{subsection.5.1}% 18
\BOOKMARK [3][-]{subsubsection.5.1.3}{Learning Sequentially}{subsection.5.1}% 19
\BOOKMARK [3][-]{subsubsection.5.1.4}{Learning in a Dynamic Environment}{subsection.5.1}% 20
\BOOKMARK [2][-]{subsection.5.2}{Random Scenarios}{section.5}% 21
\BOOKMARK [1][-]{section.6}{Conclusions }{}% 22
